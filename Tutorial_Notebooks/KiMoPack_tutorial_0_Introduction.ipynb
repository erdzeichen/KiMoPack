{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Introduction\n",
    "\n",
    "This notebook is an introduction to transient absorption spectroscopy using KiMoPack <br>\n",
    "In contrast to the other tutorials we are using artificial data for this analysis to <br>\n",
    "enable the user to judge the success of the analysis. <br>\n",
    "For this training we will be using a dataset was generated by creating a reaction of <br>\n",
    "the type A->B->C and spectra as shown in these images. We will try to enable the user <br> \n",
    "to perform a similar analysis. The following tutorials 1-5 (or more if some were added <br>\n",
    "since writing this) use then real data.\n",
    "\n",
    "<img src=\"img/Intro_tutorial.png\" style=\"width:500px;\">\n",
    "\n",
    "## The steps of an analysis\n",
    "\n",
    "A typical analysis involves the following steps:\n",
    "\n",
    "1. Data Import\n",
    "2. Data Shaping\n",
    "3. (Optional) comparative analysis\n",
    "4. Modelling\n",
    "5. Reporting\n",
    "\n",
    "In KiMoPack the analysis is normally guided by the workflow tools that can be found here: \n",
    "https://github.com/erdzeichen/KiMoPack/tree/main/Workflow_tools\n",
    "of directly downloaded by calling the function: \n",
    "\n",
    "``` python\n",
    "    import KiMoPack\n",
    "    KiMoPack.download_notebooks()\n",
    "```\n",
    "Alternatively the following function downloads the notebook and all the Tutorial Notebooks and training data:\n",
    "\n",
    "``` python\n",
    "    import KiMoPack\n",
    "    KiMoPack.download_all()\n",
    "```\n",
    "\n",
    "## Python Imports\n",
    "KiMoPack is a python package that heavily relies on the python data analysis infrastructure.<br>\n",
    "Each notebook starts with series of imports. Here we add an option that recognizes if this notebook<br>\n",
    "is run on Colab. In this case we download the necessary datafiles.<br> \n",
    "\n",
    "**Note** Limitations on Colab are the interactive functions. So Chirp correction and clicking into the figures does not work (yet)<br>\n",
    "\n",
    "The whole program is contained in the single file **plot_func** that typically is imported as **pf** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "#---This section is importing KiMoPack and tries to catch when it is not installed, in which case it installs it from pypi\n",
    "try:\n",
    "    import KiMoPack.plot_func as pf\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print('We now try to install KiMoPack')\n",
    "    !pip install kimopack\n",
    "    !pip install python-pptx\n",
    "    try: #Now that we have installed, lets try to import again\n",
    "        import KiMoPack.plot_func as pf\n",
    "    except: #seems like we need to restart the server\n",
    "        print(\"\\n\\n#-------\\n We forced a restart \\n Please run this cell again!\\n\\n \")\n",
    "        os._exit(00)  #dirty trick to kill the server and force a restart  \n",
    "\n",
    "#--- This section is importing additional modules needed in this tutorial\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib,lmfit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-----this section is downloading the files and sets the paths to the data.\n",
    "if \"google.colab\" in sys.modules:    #Check we are local or on Colab\n",
    "    pf.download_all('Introduction') # download the datafiles\n",
    "    use_inline=True\n",
    "    path_to_files = os.sep.join([os.getcwd(), \"Tutorial_Notebooks\",\"Data\", \"Introduction\"])\n",
    "    sys.path.append(os.path.join('KiMoPack','Tutorial_Notebooks'))# add the path to the function file\n",
    "    pf.halfsize=True\n",
    "    pf.changefonts()\n",
    "else:\n",
    "    path_to_files = os.sep.join([os.getcwd(), \"Data\", \"Introduction\"])\n",
    "    use_inline=True\n",
    "if use_inline:\n",
    "    %matplotlib inline\n",
    "    pf.halfsize=True\n",
    "    pf.changefonts()\n",
    "else:\n",
    "    #%matplotlib qt\n",
    "    %matplotlib tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Data Import\n",
    "\n",
    "In KiMoPack data is imported and handled in form of a Pandas DataFrame. <br>\n",
    "The data is either read from disc by one of the import functions or given <br>\n",
    "to the function in form of a dataframe that is commonly called \"ds\" for Dataset.<br> \n",
    "The manual import is used as a backup or as a way to start fitting with intermediary results. <br>\n",
    "Please see the end of this tutorial in the section \"Fitting of oscillations\" for an example. \n",
    "\n",
    "In this tutorial we will focus on the main import function **pf.TA** that is used<br>\n",
    "to create a single transient absorption object. For work with many single scans please <br> \n",
    "see Tutorial 4 \"Single scan handling\", for comparative work please see tutorial 3 \"Compare Fit\".\n",
    "\n",
    "All import function have a wide variety of options to adapt to different file types and shapes.<br>\n",
    "Most file types and shapes can be imported naturally. There is also the option to provide a **conversion_function**.<br>\n",
    "This function is an API that makes importing files of different shapes more comfortable and can e.g. <br>\n",
    "adjust names and formats very flexibly. Please see the documentation of the function with \"pf.TA?\" or the online documentation under:\n",
    "    https://kimopack.readthedocs.io/en/latest/Opening.html\n",
    "for more details. \n",
    "\n",
    "## Finding the Filename and path\n",
    "There are two general ways to provide the name and path to the files that are to be investigated. \n",
    "    \n",
    "1. Either the filename and path to the file is provided. In this case the path is <br>\n",
    "        either a single word (e.g. \"Data\" if all the data is in the relative folder <br>\n",
    "        \"data\" or a path to files. All the usual ways to handle a path should work. <br>\n",
    "        I prefer to create a path by creating a platform independent string \n",
    "2. instead of a filename the word **gui** is used, in which case a TKinter Gui opens <br> \n",
    "    and allows the user to select a file (and path) I recommend that directly after <br>\n",
    "    the file is opened the use changes the work **gui** into **recent**. Because then the <br> \n",
    "    code will reopen last file that was opened before with the gui (permitting restarting)\n",
    "\n",
    "In this example we will use the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta=pf.TA(\"con_1.SIA\",path=path_to_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "If no errors appear the import was most likely successful and we can continue with the inspection and shaping of data. <br> \n",
    "If there are troubles during or the data does not look like it should, the imported data is stored in the DataFrame **ta.ds_ori**  <br> \n",
    "and checking if this looks correct with \"ta.ds_ori.head()\" is a very good first step for finding the right input parameters.<br>\n",
    "\n",
    "**Note**: there are on some systems deprecation warnings appearing. Those can be safely ignored. The concept of KiMoPack is not to lock the version of the modules used, meaning that I constantly update the code to new (and changing functions). This is done to enable the users to use KiMoPack in many different scenarios and with many packages.\n",
    "\n",
    "\n",
    "## Data Inspection, shaping and RAW plotting\n",
    "The first step is usually to visually inspect the data. <br> \n",
    "In KiMoPack we use three plotting functions for all plotting tasks and three functions for comparative plotting (see Tutorial 3)\n",
    "``` python\n",
    "ta.Plot_RAW()\n",
    "ta.Plot_fit_output()\n",
    "ta.Plot_Interactive()\n",
    "```\n",
    "All plot functions plot in their standard call (as above) multiple plots simultaneously. <br> \n",
    "The first argument is a list that calls all the plots that one chooses. For RAW plotting the default is:\n",
    "``` python\n",
    "ta.Plot_RAW(range(4))\n",
    "```\n",
    "\n",
    "Here we choose to only look at the Matrix, which is plot \"0\" (see the documentation with \"ta.Plot_RAW?\" or https://kimopack.readthedocs.io/en/latest/Plotting.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.Plot_RAW(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Note** In this tutorial we use the \"inline\" plotting option. Meaning that all the plots will be in the notebook and not interactive. <br>\n",
    "If you change during the import the variable: use_inline to \"False\" and restart the notebook, you will have the option to interact with most plots. <br> This not only includes the resizing of the figures, but also to activate the option to click in the figures and print the click position.\n",
    "The options:\n",
    "``` python\n",
    "ta.intensity_range=1e-2\n",
    "ta.intensity_range=[0,1e-2]\n",
    "ta.log_scale=True\n",
    "```\n",
    "set the amplitude in the plot, first symmetric from -1e-2 to 1e-2, the second asymmetric and the last in a logarithmic scale. Plotting in a logarithmic scale is very useful for seeing small changes, but distorts the mayor scale. I usually use it to see the last changes during fitting.\n",
    "\n",
    "Now lets set the range where we want to fit with the time_limits and spectral limits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.bordercut=[400,975]\n",
    "ta.timelimits=[-0.2,500]\n",
    "ta.Plot_RAW(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "And set the interesting wavelength and time points where we want the code to plot Kinetics and spectra respectively. e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "ta.rel_wave=[430,487,525,640,720,820,900,950]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "During the import these values are set automatically:\n",
    "``` python\n",
    "ta.rel_wave = np.arange(300,1000,100)\n",
    "ta.rel_time = [0.2,0.3,0.5,1,3,10,30,100,300,1000,3000,9000]\n",
    "```\n",
    "The parameter \"wavelength_bin\" set the width of the spectral bins. The parameter \"time_width_percent\" sets a percentual binning for the times.\n",
    "additional shaping options include rebinning in the spectral range \"wave_nm_bin\" or in energy scale \"equal_energy_bin\". See:<br>\n",
    "https://kimopack.readthedocs.io/en/latest/Plotting.html#plot-shaping-options-without-influence-on-the-fitting and<br>\n",
    "https://kimopack.readthedocs.io/en/latest/Shaping.html for more details\n",
    "\n",
    "Lets plot all of the RAW spectra: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.Plot_RAW()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Note** The filename is the standard title of the plots. The Plot function can take other titles. Alternatively changing the variable \"ta.filename\" can be used to change the title permanently.\n",
    "\n",
    "``` python\n",
    "ta.Save_Powerpoint(save_Fit=False,title='Tutorial plot')\n",
    "```\n",
    "This would create these plots and place them all on a powerpoint slide and save this slide.\n",
    "\n",
    "# Fitting of Data\n",
    "One of the main purposes of KiMoPack is to make a Global analysis of the data. As can be seen from the results of the SVD (last plot in the RAW plotting) the independent extraction of the spectra using the usual approach $ U\\,\\times\\,\\sum\\,\\times\\,V^{T} = M$ leads to vectors that are extracted from the data only and not physically meaningfull. <br> \n",
    "1. KiMoPack is using a parametric model function **ta.mod** to prepare a \"concentration matrix\" $C(t)$.\n",
    "2. In the standard usage the spectral matrix (called \"DAC\" in KiMoPack) is then calculated with np.linalg.lstsq so that the calculated matrix **AC** is $C(t)\\,\\times\\,DAC(\\lambda)=AC$.\n",
    "3. Then an error matrix **AE** is calculated that is the difference between the (shaped) measured matrix **A** and the calculated matrix **AC**\n",
    "4. Then the parameter of the **ta.mod** are modulated to minimize the sum of the squared **AE**\n",
    "\n",
    "This fitting process has a huge amount of options that include the providing of external spectra. If a sufficient amount of external spectra are provided this fitting process changes into a linear combination analysis. named switches like \"ext_spectra_scale\", \"extt_spectra_shift\"or \t\t\"ext_spectra_guidechange how they are handled. <br>\n",
    "e But let's start at the beginning:\n",
    "\n",
    "## choosing of the model function\n",
    "KiMoPack can either use one of the 3 **named functions**:\n",
    "``` python\n",
    "ta.mod = 'exponential' #or 'paral'\n",
    "ta.mod = 'consecutive'\n",
    "ta.mod = 'full_consecutive'\n",
    "```\n",
    "or an externally provided **external fitting function** as are provided in the file \"function_library.py\" and summarized in \"Function_library_overview.pdf\". The provided external fitting functions include linear and non linear models that cover pretty much any of the possible models with 3 or 4 species including some vibrational models<br>\n",
    ". Most function know switches like \"background\" = fit the background, \"infinite\" = non decaying species, \"explicit_gs\" = make the bleach an explicit speci. <br> But in general the external function can be pretty much anything that is needed. It gets a time vector, (at which point the function should return an entrance) and a pardf = Dataframe with the parameter from the fitting point. **It is expected to return the C(t)** and anything else is free. <br> We will look into these functions a bit later in this tutorial. Important to mention is that there is no difference in how this is handled.\n",
    "\n",
    "In this tutorial we start with a **Decay analysis**\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='exponential'       # Choose a model here 'exponential' to get simple exponential decays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Next we create a parameter object and choose appropiate guess values.<br>\n",
    "I use the limiting options \"min\" and \"max\" and typically freeze with **vary=False**: <br>\n",
    "the starting time \"t0\" and <br>\n",
    "the instrument response time 'resolution'<br>\n",
    "Usually the RAW plot of the kinetics is a good starting point to read the initial guesses (as are previous informations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.Plot_RAW(1)\n",
    "ta.par=lmfit.Parameters()                                       # create empty parameter object\n",
    "ta.par.add('k0',value=1/0.14,vary=True)                  \n",
    "ta.par.add('k1',value=1/2.35,vary=True)             \n",
    "ta.par.add('k2',value=1/40,vary=True)   \n",
    "###-------Adding instrument parameter, here frozen---------------\n",
    "ta.par.add('t0',value=0,min=-2,max=2,vary=False)                       # Allow the arrival time to adjust? (False here)\n",
    "ta.par.add('resolution',value=0.086,min=0.04,max=0.5,vary=False)       # Allow the instrument response to adjust (False here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "now we could with \n",
    "```python\n",
    "ta.Fit_Global()\n",
    "```\n",
    "trigger a fit <br>\n",
    "However i usually use this loop to freeze all parameter and check how good my input parameter actually are.<br>\n",
    "the last function  \n",
    "``` python\n",
    "ta.Plot_fit_output()\n",
    "```\n",
    "is plotting the fit output. Like the plotting function \"ta.Plot_RAW\" the default is: \"ta.Plot_fit_output(range(7))\" but here we use for simplicity just the matrix plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in ta.par.keys():\n",
    "    ta.par[key].vary=False\n",
    "ta.Fit_Global()                                 # trigger fitting\n",
    "ta.Plot_fit_output(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Not bad for pure guesses. <br>\n",
    "I usually leave the full fitting cell together and use \"if 0:\" to turn of the starting value checking.<br>\n",
    "lets run an actual fit followed by a full out put of ta.Plot_fit_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='exponential'       # Choose a model here 'exponential' to get simple exponential decays\n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('k0',value=1/0.14,vary=True)                  \n",
    "par.add('k1',value=1/2.35,vary=True)             \n",
    "par.add('k2',value=1/40,vary=True)   \n",
    "###-------Adding instrument parameter, here frozen---------------\n",
    "par.add('t0',value=0,min=-2,max=2,vary=False)                       # Allow the arrival time to adjust? (False here)\n",
    "par.add('resolution',value=0.086,min=0.04,max=0.5,vary=False)       # Allow the instrument response to adjust (False here)\n",
    "if 0:\n",
    "    for key in par.keys():\n",
    "        par[key].vary=False\n",
    "ta.par=par                                                     # write parameter object into file for fitting\n",
    "ta.Fit_Global()                                 # trigger fitting\n",
    "\n",
    "plt.close('all')\n",
    "ta.Plot_fit_output([0,1,4,5])                            # plot the fit output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The output is stored in **ta.re** (a dictionay) with \n",
    "* **\"c\"** = $c(t)$\n",
    "* **\"DAC\"** = $DAC(\\lambda)$\n",
    "* **\"A\"**, **\"AC\"**, **\"AE\"**\n",
    "* a large number of other things\n",
    "   \n",
    "The plots I usually check are:\n",
    "\n",
    "    1 Decay associated spectra (called **DAC**)\n",
    "        a. middle: as calculated\n",
    "        b. right: spectra multiplied by maximum of c(t) for check if it should be visible\n",
    "        c. left: normalized\n",
    "    2. The spectral axis summed\n",
    "    5. The fitted Matrixes\n",
    "    6. The c(t) that was actually used\n",
    "Together with the metrix $R^2$ and $\\chi^2$<br>\n",
    "Other plotting options include the residuals(6), kinetics(2), spectra(3)\n",
    "\n",
    "## Target Analysis\n",
    "The next model one typically tries is a consecutive model (A->B->C) This only requires to change the model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='consecutive'\n",
    "ta.Fit_Global()\n",
    "ta.Plot_fit_output([0,1,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Here it is still visible that the \"species\" have a bleach and a stimulated emission.<br> \n",
    "Next I would try to add the ground state explicitely by adding the keyword **explicit_GS**<br>\n",
    "I usually keep the fitting cell together as one unit and work on the parameters.<br>\n",
    "\n",
    "**compare the last plot containing the c(t) to understand the difference** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='consecutive'       # Choose a model here 'exponential' to get simple exponential decays\n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('k0',value=1/0.14,vary=True)                  \n",
    "par.add('k1',value=1/2.35,vary=True)             \n",
    "par.add('k2',value=1/40,vary=True)   \n",
    "###-------Adding instrument parameter, here frozen---------------\n",
    "par.add('t0',value=0,min=-2,max=2,vary=False)                       # Allow the arrival time to adjust? (False here)\n",
    "par.add('resolution',value=0.086,min=0.04,max=0.5,vary=False)       # Allow the instrument response to adjust (False here)\n",
    "if 0:\n",
    "    for key in par.keys():\n",
    "        par[key].vary=False\n",
    "ta.par=par                                                     # write parameter object into file for fitting\n",
    "ta.Fit_Global()                                 # trigger fitting\n",
    "\n",
    "plt.close('all')\n",
    "ta.Plot_fit_output([0,1,4,5])                            # plot the fit output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "the longer timepoints are very well represented, but there are still some errors in the early times. So we permit the laser arrival time, and the instrument response function free again and change the model to \"full_consecutive\".\n",
    "\n",
    "The difference is that instead of using a rise for the first species and then a consecutive approach, we are now modelling the decay by sampling the excitation with a \"pulse\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='full_consecutive'    \n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('k0',value=1/0.101,vary=True)                  \n",
    "par.add('k1',value=1/2.4,vary=True)             \n",
    "par.add('k2',value=1/39,vary=True)   \n",
    "par.add('t0',value=0,min=-2,max=2,vary=False)                       # Allow the arrival time to adjust? (False here)\n",
    "par.add('resolution',value=0.086081,min=0.04,max=0.5,vary=False)       # Allow the instrument response to adjust (False here)\n",
    "par.add('explicit_GS')\n",
    "\n",
    "ta.par=par                                                     # write parameter object into file for fitting\n",
    "ta.Fit_Global()                                 # trigger fitting\n",
    "ta.Plot_fit_output([0,1,4,5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "There is only a small bleach left in the species associated spectra which is excellent.<br>\n",
    "Many optimizations are now possible, <br>\n",
    "one would be to give each of the fitted parameters a limit and using the global optimizer \"AMPGO\" does solve this problem. However, while Ampgo is one of the most efficient global codes, it is still slow enough for a coffee<br> \n",
    "another highly recommended approach would be to provide additional information such as external spectra. Here we could make a guess for a gaussian.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def gauss(t,sigma=35,mu=545,amp=0.85):\n",
    "\t'''Gauss function'''\n",
    "\ty=np.exp(-0.5*((t-mu)**2)/sigma**2)\n",
    "\ty/=sigma*np.sqrt(2*np.pi)\n",
    "\treturn y*amp\n",
    "\n",
    "wave=ta.re['A'].columns.values\n",
    "df=pd.DataFrame(gauss(t=wave),index=wave)\n",
    "df.columns=['GS']\n",
    "df.sort_index(inplace=True)\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "and add it as the ground state spectrum to the modelling.<br>\n",
    "Here we use the switch **par.add('ext_spectra_guide')** That converts the spectrum from \"must be like this\" to \"should be some close to this\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.mod='full_consecutive'    \n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('k0',value=1/0.1,vary=True)                  \n",
    "par.add('k1',value=1/2.5,vary=True)             \n",
    "par.add('k2',value=1/40,vary=True)   \n",
    "par.add('t0',value=0,min=-2,max=2,vary=True)                       # Allow the arrival time to adjust? (False here)\n",
    "par.add('resolution',value=0.086081,min=0.04,max=0.5,vary=True)       # Allow the instrument response to adjust (False here)\n",
    "par.add('explicit_GS')\n",
    "\n",
    "#par.add('ext_spectra_scale',value=1,vary=True)\n",
    "#par.add('ext_spectra_shift',value=0,vary=False)\n",
    "par.add('ext_spectra_guide')\n",
    "ta.par=par\n",
    "ta.Fit_Global(ext_spectra=df)\n",
    "#ta.Plot_fit_output([0])\n",
    "ta.Plot_fit_output([0,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we can compare the time evolution of the components with the species associated spectra that were put into the data.\n",
    "<img src=\"img/Intro_tutorial.png\" style=\"width:500px;\">\n",
    "It is close, but still not perfect, and this is how it is in reality often. However adding the external spectrum made the data again a little bit better and with further modelling the representation gets even better.\n",
    "\n",
    "For the next step it is a good idea to transfer the optimum parameter (stored in ta.par_fit) to the starting parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta.par=ta.par_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Error Analysis.\n",
    "\n",
    "It is a very imporant step to check the confidence interval, that unfortunately does take quite some time. (typically 100x the time for  a single optimization. It is generally a good idea to save the project before you do that with ta.Save_project() to not loose the prior work. The following cell shows the result of this run. The file \"con_1_solved.hdf5\" contains the project with the result for you to inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#ta.Fit_Global(confidence_level=0.95)\n",
    "#Saved 20min\n",
    "ta=pf.TA('con_1_solved.hdf5',path=path_to_files)\n",
    "ta.filename='Solved_file.hdf5'\n",
    "ta.Print_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Report the results\n",
    "We can again create a Powerpoint to summarize the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save the results\n",
    "plt.close('all')\n",
    "ta.Save_Powerpoint(title='Tutorial plot after Fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Typical data corrections (chirp,....)\n",
    "\n",
    "In real data, the measured signals are not as nice and clear as we have worked with up to now.<br>\n",
    "For 'con_2.SIA','con_3.SIA','con_4.SIA','con_5.SIA' 'con_6.SIA' typical disturbances were introduced. <br>\n",
    "for which additional complications such as noise, chirp and crossphase modulation was added.<br>\n",
    "\n",
    "1. Use the function \"Cor_chirp\" that is part of the ta object to correct the chrip in \"con_2.SIA\".\n",
    "2.  Apply the same chirp correction (either via the file name or the ta.fitcoeff to the following files. You do want to use ta.intensity range and ta.log_plot=True/False to make the development in this file visible\n",
    "1. In file con_3.SIA you additionally need to adress the spectral limits using \"bordercut\"\n",
    "1. In file con_4.SIA we have typical artifacts and Cross-Phase-Modulation. Use \"ignore_time_region\" to blind this out \n",
    "1. in File con_5.SIA we have to additionally reject a spectral region in which the pump laser light scattered into the detector, as is often the case if measuring e.g. nano particles.\n",
    "1. In the final file con_6.SIA our initial state has some Frank condon type oscillations. Fit the data with the kinetics, and find the oscillations in the Plot_Fit_output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_2.SIA',path=path_to_files)\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=True\n",
    "ta1.Plot_RAW(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_2.SIA',path=path_to_files)\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=True\n",
    "ta1.timelimits=[-0.2,500]\n",
    "ta1.rel_wave=[430,487,525,640,720,820,900,950]\n",
    "ta1.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "\n",
    "ta1.Plot_RAW(0,title='before_chirp')\n",
    "ta1.Cor_Chirp()\n",
    "ta1.Plot_RAW(0,title='after_chirp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_3.SIA',path=path_to_files)\n",
    "ta1.Cor_Chirp(chirp_file='con_2_chirp.dat')\n",
    "\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=True\n",
    "ta1.timelimits=[-0.2,500]\n",
    "ta1.rel_wave=[430,487,525,640,720,820,900,950]\n",
    "ta1.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "\n",
    "ta1.Plot_RAW(0,title='before bordercut')\n",
    "ta1.bordercut=[390,1150]\n",
    "ta1.Plot_RAW(0,title='after bordercut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_4.SIA',path=path_to_files)\n",
    "chirp=[-1.29781491e-11,4.72546618e-08,-6.36421133e-05,3.77396295e-02,-8.08783621e+00]\n",
    "ta1.Cor_Chirp(fitcoeff=chirp)\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=True\n",
    "ta1.timelimits=[-0.2,500]\n",
    "ta1.bordercut=[390,1150]\n",
    "ta1.rel_wave=[430,487,525,640,720,820,900,950]\n",
    "ta1.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "\n",
    "ta1.Plot_RAW(0,title='with artifact')\n",
    "ta1.ignore_time_region=[-0.15,0.1]\n",
    "ta1.Plot_RAW(0,title='without artifact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Note** instead of a single region multiple regions can be defined\n",
    "``` python\n",
    "ta1.ignore_time_region=[[-0.15,0.1],[10,12]]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_5.SIA',path=path_to_files)\n",
    "chirp=[-1.29781491e-11,4.72546618e-08,-6.36421133e-05,3.77396295e-02,-8.08783621e+00]\n",
    "ta1.Cor_Chirp(fitcoeff=chirp)\n",
    "\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=True\n",
    "ta1.timelimits=[-0.2,500]\n",
    "ta1.bordercut=[390,1150]\n",
    "ta1.rel_wave=[430,487,525,640,720,820,900,950]\n",
    "ta1.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "ta1.ignore_time_region=[-0.15,0.1]\n",
    "\n",
    "ta1.Plot_RAW(0,title='with laser scatter')\n",
    "ta1.scattercut=[525,580]\n",
    "ta1.Plot_RAW(0,title='without laser scatter')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "**Note** instead of a single region multiple regions can be defined\n",
    "``` python\n",
    "ta1.scattercut=[[525,580],[780,820]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Advanced modelling, Let's look on some oscillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1=pf.TA('con_6.SIA',path=path_to_files)\n",
    "chirp=[-1.29781491e-11,4.72546618e-08,-6.36421133e-05,3.77396295e-02,-8.08783621e+00]\n",
    "ta1.Cor_Chirp(fitcoeff=chirp)\n",
    "\n",
    "ta1.intensity_range=0.005\n",
    "ta1.log_scale=False\n",
    "ta1.timelimits=[-0.2,500]\n",
    "ta1.bordercut=[390,1150]\n",
    "ta1.scattercut=[525,580]\n",
    "ta1.rel_wave=[430,487,525,640,720,820,900,950]\n",
    "ta1.rel_time=[-0.1,-0.02,0.035,0.2,0.5,2,14,22,92,160]\n",
    "ta1.ignore_time_region=[-0.15,0.1]\n",
    "ta1.Plot_RAW(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta1.mod='full_consecutive'    \n",
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('k0',value=1/0.100143,vary=True)                  \n",
    "par.add('k1',value=1/2.496702,vary=True)             \n",
    "par.add('k2',value=1/39.963222,vary=True)   \n",
    "par.add('t0',value=0,min=-2,max=2,vary=False)                       # Allow the arrival time to adjust? (False here)\n",
    "par.add('resolution',value=0.086081,min=0.04,max=0.5,vary=False)\n",
    "par.add('explicit_GS')\n",
    "ta1.par=par\n",
    " \n",
    "ta1.Fit_Global()\n",
    "ta1.Plot_fit_output([0,4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Now we have the main Kinetics and can subtract them. Here simply use the residuals as the next matrix to be fitted and adjust the shaping parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ta2=ta1.Copy()\n",
    "ta2.ds=ta1.re['AE']\n",
    "\n",
    "ta2.intensity_range=3e-4\n",
    "ta2.rel_wave=[620,700,740,800,830,860]\n",
    "ta2.timelimits=[0.1,10]\n",
    "ta2.Plot_RAW(0,scale_type='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As an alternative one could have subtracted all (or some) of the contributions using this approach:\n",
    "``` python\n",
    "    dicten=pf.Species_Spectra(ta1) # Extract each of the species as a matrix\n",
    "    ta3=ta1.Copy()                 # Make a copy of the project to test\n",
    "    ta3.ds=ta1.re['A']-dicten[1]-dicten[2]-dicten['GS'] #subtract one or multiple of the species.\n",
    "```\n",
    "\n",
    "Now we load the function file and select a model from it. <br>\n",
    "Optimizing follows the same procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import function_library as func\n",
    "ta2.mod=func.oscil_comp   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "par=lmfit.Parameters()                                       # create empty parameter object\n",
    "par.add('f0',value=1.00561,vary=True)                  \n",
    "par.add('tk0',value=1/2.8725,vary=True,min=1/4,max=4)\n",
    "par.add('S0',value=0.975956,vary=True ,min=0,max=1)\n",
    "ta2.par=par\n",
    "ta2.ignore_time_region=[-0.15,0.25]\n",
    "#ta2.Fit_Global(other_optimizers='least_squares')\n",
    "ta2.Fit_Global()\n",
    "\n",
    "plt.close('all')\n",
    "ta2.error_matrix_amplification=1\n",
    "ta2.Plot_fit_output([0,4],scale_type='linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "As does calculating the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#This takes about 2min\n",
    "#ta2.Fit_Global(confidence_level=0.95)\n",
    "\n",
    "ta2=pf.TA('Fitted_Oscillations_with_confidence.hdf5',path=path_to_files)\n",
    "ta2.Print_Results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Finally  we combine the normal model and the oscillation model and make a combined fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "reload(func)\n",
    "ta1.mod=func.manconsec_oscil\n",
    "ta1.par=ta1.par_fit\n",
    "for key in ['f0','tk0','S0']:\n",
    "    ta1.par.add(key,value=ta2.par_fit[key].value)\n",
    "    ta1.par[key].vary=False\n",
    "ta1.par['S0'].min=0\n",
    "ta1.par['S0'].max=1\n",
    "ta1.Fit_Global()\n",
    "ta1.Plot_fit_output()"
   ]
  }
 ],
 "metadata": {
  "ipub": {
   "titlepage": {
    "author": "Jens Uhlig",
    "email": "jens.uhlig@chemphys.lu.se",
    "logo": "http://www.jensuhlig.de//hot_warm_cold.png",
    "subtitle": "Main Worksheet",
    "title": "Transient Absorption Worksheet"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
